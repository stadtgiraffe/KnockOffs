{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from DeepKnockoffs import KnockoffMachine\n",
    "from DeepKnockoffs import GaussianKnockoffs\n",
    "import data\n",
    "import parameters\n",
    "from data import load_IHDP_data"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "Load IHDP data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_train, data_test = load_IHDP_data(type_a=True, i=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second-order knockoffs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute pairwise correlation: 0.459.\n"
     ]
    }
   ],
   "source": [
    "# Compute the empirical covariance matrix of the training data\n",
    "SigmaHat = np.cov(data_train['x'], rowvar=False)\n",
    "\n",
    "# Initialize generator of second-order knockoffs\n",
    "second_order = GaussianKnockoffs(SigmaHat, mu=np.mean(data_train['x'],0), method=\"sdp\")\n",
    "\n",
    "# Measure pairwise second-order knockoff correlations\n",
    "corr_g = (np.diag(SigmaHat) - np.diag(second_order.Ds)) / np.diag(SigmaHat)\n",
    "\n",
    "print('Average absolute pairwise correlation: %.3f.' %(np.mean(np.abs(corr_g))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep knockoff machine\n",
    "\n",
    "The default parameters of the machine are set below, as most appropriate for the specific built-in model considered.\n",
    "The figures in the paper were obtained by setting the number of epochs to 1000 and the learning rate to 0.001, while in order to reduce the runtime this notebook uses the values 100 and 0.01 respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Load the built-in multivariate Student's-t model and its default parameters\n",
    "# The currently available built-in models are:\n",
    "# - gaussian : Multivariate Gaussian distribution\n",
    "# - gmm      : Gaussian mixture model\n",
    "# - mstudent : Multivariate Student's-t distribution\n",
    "# - sparse   : Multivariate sparse Gaussian distribution\n",
    "model = \"mstudent\"\n",
    "# Number of features\n",
    "n = data_train['x'].shape[0]\n",
    "p = data_train['x'].shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the default hyperparameters for this model\n",
    "training_params = parameters.GetTrainingHyperParams(model)\n",
    "\n",
    "# Set the parameters for training deep knockoffs\n",
    "pars = dict()\n",
    "# Number of epochs\n",
    "pars['epochs'] = 100\n",
    "# Number of iterations over the full data per epoch\n",
    "pars['epoch_length'] = 100\n",
    "# Data type, either \"continuous\" or \"binary\"\n",
    "pars['family'] = \"continuous\"\n",
    "# Dimensions of the data\n",
    "pars['p'] = p\n",
    "# Size of the test set\n",
    "pars['test_size']  = 0\n",
    "# Batch size\n",
    "pars['batch_size'] = int(0.5*n)\n",
    "# Learning rate\n",
    "pars['lr'] = 0.01\n",
    "# When to decrease learning rate (unused when equal to number of epochs)\n",
    "pars['lr_milestones'] = [pars['epochs']]\n",
    "# Width of the network (number of layers is fixed to 6)\n",
    "pars['dim_h'] = int(10*p)\n",
    "# Penalty for the MMD distance\n",
    "pars['GAMMA'] = training_params['GAMMA']\n",
    "# Penalty encouraging second-order knockoffs\n",
    "pars['LAMBDA'] = training_params['LAMBDA']\n",
    "# Decorrelation penalty hyperparameter\n",
    "pars['DELTA'] = training_params['DELTA']\n",
    "# Target pairwise correlations between variables and knockoffs\n",
    "pars['target_corr'] = corr_g\n",
    "# Kernel widths for the MMD measure (uniform weights)\n",
    "pars['alphas'] = [1.,2.,4.,8.,16.,32.,64.,128.]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Where to store the machine\n",
    "checkpoint_name = \"tmp/\" + model\n",
    "\n",
    "# Where to print progress information\n",
    "logs_name = \"tmp/\" + model + \"_progress.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Initialize the machine\n",
    "machine = KnockoffMachine(pars, checkpoint_name=checkpoint_name, logs_name=logs_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the machine\n",
    "print(\"Fitting the knockoff machine...\")\n",
    "machine.train(data_train['x'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}